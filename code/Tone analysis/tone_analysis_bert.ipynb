{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxAuOp6xC-cM",
        "outputId": "cb35f213-eb92-4194-bc6b-fed15cd60f70"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers\n",
        "\n",
        "# import libraries\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import AutoConfig\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import spacy\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "2    31421\n",
            "0    16947\n",
            "1    11632\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df1=pd.read_csv(\"generic_sentiment_dataset_50k.csv\")\n",
        "df2=pd.read_csv(\"generic_sentiment_dataset_10k.csv\")\n",
        "\n",
        "# combine the two datasets\n",
        "df = pd.concat([df1, df2], ignore_index=True)\n",
        "print(df['label'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>positive</td>\n",
              "      <td>16lbs is still a huge achievement though</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>Good</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>Plz plz do not buy this phone..this is a jugad...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>Design:\\nI bought this phone in moonlight col...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34495</th>\n",
              "      <td>positive</td>\n",
              "      <td>Improve battery life but it's camera and finge...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34496</th>\n",
              "      <td>positive</td>\n",
              "      <td>has just finished reading Twilight and thought...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34497</th>\n",
              "      <td>negative</td>\n",
              "      <td>Tuch working very poor, bad camera quality</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34498</th>\n",
              "      <td>positive</td>\n",
              "      <td>In the reporting period , the company 's opera...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34499</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Good product under 10k</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34500 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      sentiment                                               text  label\n",
              "0      positive           16lbs is still a huge achievement though      2\n",
              "1      positive                                               Good      2\n",
              "2      negative  Plz plz do not buy this phone..this is a jugad...      0\n",
              "3       neutral                                               Good      1\n",
              "4      positive   Design:\\nI bought this phone in moonlight col...      2\n",
              "...         ...                                                ...    ...\n",
              "34495  positive  Improve battery life but it's camera and finge...      2\n",
              "34496  positive  has just finished reading Twilight and thought...      2\n",
              "34497  negative         Tuch working very poor, bad camera quality      0\n",
              "34498  positive  In the reporting period , the company 's opera...      2\n",
              "34499   neutral                             Good product under 10k      1\n",
              "\n",
              "[34500 rows x 3 columns]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Take a subset of the data for faster processing\n",
        "# 34500 rows of data from the original dataset\n",
        "# 11500 rows for each of the 3 classes (positive, negative, neutral)\n",
        "# set random seed for reproducibility\n",
        "\n",
        "seed = 42\n",
        "df_clean = df.dropna()  # drop rows with missing values\n",
        "df_clean = df_clean.sample(frac=1).reset_index(drop=True)           # shuffle the data\n",
        "df_clean = df_clean.groupby('sentiment').head(11500)          # take 11500 rows from each class\n",
        "df_clean = df_clean.sample(frac=1).reset_index(drop=True)     # shuffle the data again\n",
        "df_clean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "xPpsvPjEC-cO"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Data splits\n",
        "# -------------\n",
        "# split the data into train, validation and test sets\n",
        "seed1 = 42\n",
        "seed2 = 52\n",
        "X_train_and_val, X_test, y_train_and_val, y_test = train_test_split(df_clean.drop('label', axis=1), df_clean['label'], test_size=0.2, random_state=seed1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_and_val, y_train_and_val, test_size=X_test.shape[0], random_state=seed2)\n",
        "\n",
        "X_train_and_val_nn = X_train_and_val['text']\n",
        "X_train_nn = X_train['text']\n",
        "X_val_nn = X_val['text']\n",
        "X_test_nn = X_test['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# check if there are any null values\n",
        "print(X_train_and_val_nn.isnull().sum())\n",
        "print(X_train_nn.isnull().sum())\n",
        "print(X_val_nn.isnull().sum())\n",
        "print(X_test_nn.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### BERT Model (Optimized) - with Smart Padding\n",
        "In order to improve over the previous model in terms of computatioal efficiency, smart padding technique is used where the padding is dynamically changed based on the length of the sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "e16dab1f2b3d40dbb4e9831bae53f60e",
            "d6d29ba521e34d68b93125172e1fa0bd",
            "95dff7dae4854e00bff18e3b95532180",
            "faf80d9976dc4afeb953a8e419ace17c",
            "86f68f17d8f645d3952a35f86a29eb13",
            "f9575d7bb42c421cab9753a1878faa50",
            "f803588ca5d840028855454d6269ff60",
            "6e3607b7dc614e638968237b60d57221",
            "cce020115ed24d80ac88d8c89f141360",
            "aff5a0e8fbc54b72b00e763f397fb289",
            "f06b651a7b7f45a39274b4f374e574c8",
            "f4d929043b6345909fa0ea2b11d9ae5f",
            "b85a79a33f2d4547a32897bcf663595e",
            "2065b6339d8746b0a335396d3a16dd11",
            "1f9924c7bbb543ca8a7d167e3990f55b",
            "a4b245840eb6414d90ac953fe77f1e0b",
            "1cc5c4ee950846c6ba1d25d87301499c",
            "15a4f7ab5cd24a47af482904fe4c1b17",
            "d475e4affb484953a77d12afb0b85eab",
            "dd80c68536ed4d51b118d667e8be7537",
            "c93408368361445080cdad6dddf1a3bb",
            "5e2b04fbffa946278af5d44d6c8b398d",
            "5acf2d10cb4340389667526bd91959cb",
            "213b68cdeb634b849938579906b64871",
            "57e8db1f36814abb9a81be3b8e73469f",
            "a3b71073eabb4c48831b574cb763f15a",
            "2d8b2e11406c4df58e7ba2992dacd20d",
            "bb727e9810114f459a70b319f76bebc6",
            "76c7986cbaf04f0198a99ec307a0c27e",
            "195a3375b2204004b548cdd91316e5f6",
            "67d91181b11c4dcc9a1c4e10946bef6d",
            "e3f1492a5d344d4788a6deb7c8e8d632",
            "54ffa10b88be4819acca71fa934b1678"
          ]
        },
        "id": "SxoHHWY-C-cP",
        "outputId": "a780de5e-c4c9-499e-a9d6-b33ae00fecff"
      },
      "outputs": [],
      "source": [
        "# Load the BERT tokenizer.\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1wCivCZC-cP",
        "outputId": "ac9c3a9e-c3f7-4ec7-816c-e60802091d3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizing 20,700 training samples...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|▏         | 273/20700 [00:00<00:07, 2725.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Tokenized 0 samples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 1412/20700 [00:00<00:07, 2690.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Tokenized 1,000 samples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 2736/20700 [00:01<00:07, 2509.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Tokenized 2,000 samples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 3588/20700 [00:01<00:06, 2687.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Tokenized 3,000 samples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 4687/20700 [00:01<00:06, 2647.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Tokenized 4,000 samples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 5525/20700 [00:02<00:05, 2727.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Tokenized 5,000 samples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 6407/20700 [00:02<00:05, 2780.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Tokenized 6,000 samples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▍      | 7238/20700 [00:02<00:05, 2537.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Tokenized 7,000 samples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 8374/20700 [00:03<00:04, 2688.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Tokenized 8,000 samples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▌     | 9456/20700 [00:03<00:04, 2561.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Tokenized 9,000 samples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 10532/20700 [00:03<00:03, 2649.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Tokenized 10,000 samples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 11579/20700 [00:04<00:03, 2551.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Tokenized 11,000 samples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|█████▉    | 12407/20700 [00:04<00:03, 2641.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Tokenized 12,000 samples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 13490/20700 [00:05<00:02, 2655.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Tokenized 13,000 samples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 69%|██████▉   | 14322/20700 [00:05<00:02, 2702.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Tokenized 14,000 samples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|███████▍  | 15388/20700 [00:05<00:02, 2516.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Tokenized 15,000 samples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 79%|███████▉  | 16413/20700 [00:06<00:01, 2468.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Tokenized 16,000 samples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 17438/20700 [00:06<00:01, 2512.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Tokenized 17,000 samples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 18292/20700 [00:07<00:00, 2615.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Tokenized 18,000 samples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▎| 19364/20700 [00:07<00:00, 2620.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Tokenized 19,000 samples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 20455/20700 [00:07<00:00, 2691.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Tokenized 20,000 samples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20700/20700 [00:07<00:00, 2607.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DONE with 20700 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "tokens = []\n",
        "labels = []\n",
        "max_len = 256\n",
        "update_interval = 1000\n",
        "\n",
        "# Tokenize all training examples\n",
        "print('Tokenizing {:,} training samples...'.format(len(X_train_nn)))\n",
        "\n",
        "# For each training example...\n",
        "for text in tqdm(X_train_nn):\n",
        "    # Report progress.\n",
        "    if ((len(tokens) % update_interval) == 0):\n",
        "        print('  Tokenized {:,} samples.'.format(len(tokens)))\n",
        "    # Tokenize the sentence.\n",
        "    input_ids = tokenizer.encode(text=text,\n",
        "                                 add_special_tokens=True,\n",
        "                                 max_length=max_len,\n",
        "                                 truncation=True,\n",
        "                                 padding=False)\n",
        "    \n",
        "\n",
        "    # Add the tokenized result to our list.\n",
        "    tokens.append(input_ids)\n",
        "\n",
        "print('DONE with {} samples'.format(len(tokens)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooqpbTKcC-cP",
        "outputId": "ce7bd0bf-7124-42e8-ba8d-a2f4f56fbf63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shortest sample: 3\n",
            "Longest sample: 256\n"
          ]
        }
      ],
      "source": [
        "# Sort training samples by the length of their input sequence.\n",
        "train_samples = sorted(zip(tokens, y_train), key=lambda x: len(x[0]))\n",
        "print('Shortest sample:', len(train_samples[0][0]))\n",
        "print('Longest sample:', len(train_samples[-1][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "po8dvUFKC-cP",
        "outputId": "4c1bf3f5-980c-4316-885f-acea5622b34a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAsvUlEQVR4nO3deZwcVbn/8c8zk0km62QlZJ8EQghBlhDCKuIFERBFEZRFDMIVF1BU/L0AceF6xYtecblXFhGRRWVR1ossAoKILCGBANmA7NuQPTOTTGZ/fn/U6aYzmaVnMt3VPf19v179mq5T29PVNfV0nao6x9wdERERgKK4AxARkdyhpCAiIklKCiIikqSkICIiSUoKIiKSpKQgIiJJSgqSFWbmZrZvDOs93szWZGE9nzKz1Wa23cwOzdA6HjezWd09rbzPzG43sx/FHUeclBSyyMyONbMXzazSzLaY2b/M7PC44+pJ4ko+wM+AS919gLu/nom43P0Ud7+ju6fNBjO7xsz+EHcc0rFecQdQKMxsEPAo8BXgPqA38EGgLs64pNtMABZ0dWYz6+Xujd0Yj0jXuLteWXgBM4BtHUxzIbAI2Ao8CUxIGfcRYDFQCfwa+Afw72HcNcAfUqYtBxzoFYbLgN8BFcBa4EdAcRh3AfAC0S/drcBy4JSUZQ0Ffg+sC+MfShl3GjAP2Aa8CBzUzmdzYN/wvk9Y3ypgPXAz0DeMOx5YA1wObAgxfyFlOcOA/wOqgFfDZ3khjHs+rGcHsB34bBrLOxVYCFSHbfPtNuIvAr4LrAzLuTNs1z5hXYn1Lm1l3vbiugJ4D7gLGEL0w2Fj2NaPAmNTlvNcynfe0ffWmWknhhirgaeBG0jZn1p8luEhrm3AFuCfQFEYNxq4P8S/HPh6KD8ZqAcawud/o41lXxG+g2rgbeCEUD4TeCmss4Jo/+/dYt/6KvBumPc/gX3CPFWEH2Et9q/vAJuAFcB5Kcu6HfhROvt4W/Hm+yv2AArlBQwCNgN3AKcAQ1qM/ySwBJhKdAb3XeDFMG542LnPBEqAbwKNpJ8UHgJ+A/QH9gJmA18K4y4I/6xfBIqJzmTWARbG/xW4l+iAVQJ8KJRPJzo4HhHmmxX+wfq08flTk8IvgUeIEs5AooP8f4Vxx4fP9sOwvlOBmsT2Au4Jr37AAcBqQlJouZ40l1cBfDC8HwJMbyP+C8P3MwkYADwA3NXWetv7/C3i+glRYulLlPA+HT7bQODP7JqEn2PXA31731tnpn2JKGH0Bo4l2tfaSgr/RZTES8Lrg4ARJc25wPfDciYBy4CPtraPtrLcKeG7HJ2yD+8T3h8GHEn0f1FO9MPpGy227SNE/2PTiM6+nwkxlBEl/VkttvvPw3b/EFGynhLG305ICrSzj7cXb76/Yg+gkF5EB/zbiX6pNIYdeWQY9zhwUcq0RUQHrwnA54GXU8ZZWEaHSQEYGf5J+qaMPwd4Nry/AFiSMq5fmHdvYBTQTIsEFqa7CfjPFmVvE5JGK9M7sG+IfUfqPxBwFLA8vD8e2ElIaKFsQzgoFBMd3KakjEueKaSuJ2W4zeWF96uALwGDOvjungG+mjI8JcTSq7X1tvX5W8RVD5S2M88hwNaU4efY9UDf6vfWmWmB8UT7Yr+U8X+g7aTwQ+Dhlp+V6MC5qkXZVcDvW9tHW1nuvuF7OREo6eC7+AbwYItte0zK8FzgipTh64Ffpmz3RqB/yvj7gO+F97fzflJocx/vTLz59tKF5ixy90XufoG7jwUOJDrd/mUYPQH4lZltM7NtRKfmBowJ061OWY6nDndgAtEvuoqUZf+G6Iwh4b2UZdeEtwOAccAWd9/axnIvTywzLHdciLU9I4gOSnNT5nsilCds9l3r12tCPCOIEl3qZ09nO7S1PIh+mZ8KrDSzf5jZUW0sYzRR1VHCSt5Pul210d1rEwNm1s/MfmNmK82siqhKZ7CZFbcxf1vfW2emHU30HdekTNveNv1vojOmv5nZMjO7MpRPAEa32B++Q5rbx92XEB3srwE2mNk9ZjYawMz2M7NHzey9sF1+THT2nGp9yvudrQynbpet7r4jZXglre+3be7j7cWb75QUYuLui4l+lRwYilYTVekMTnn1dfcXiao4xiXmNTNLHSb65d0vZXjvlPeric4Uhqcsd5C7T0sjzNXAUDMb3Ma4a1vE28/d7+5gmZuI/kmnpcxX5u5tHcxSbST6lTc2pWxcG9Omxd1fdffTiZLkQ0S/GluzjuggkZD4hb2+9cnTW32L4cuJzkCOcPdBwHGh3PZgHR2pIPqOU/efNrepu1e7++XuPgn4OPAtMzuBaH9Y3mJ/GOjupyZm7SgQd/+Tux9LtJ2dqGoNol/si4HJYbt8hz3bJkPMrH/K8Hii77eldvfxduLNa0oKWWJm+5vZ5WY2NgyPI6rGeTlMcjNwlZlNC+PLzOysMO6vwDQzO8PMegFfZ9cD/zzgODMbb2ZlRKftALh7BfA34HozG2RmRWa2j5l9qKOYw7yPAzea2RAzKzGzxIHqt8CXzewIi/Q3s4+Z2cAOltkc5v2Fme0VPusYM/toGvE0EdXlXxN+Ve9PVLWWaj1RXXKHzKy3mZ1nZmXu3kBUl97UxuR3A980s4lmNoDo1+q9nv4dQ+nENZAoYW4zs6HAD9Jcdpe5+0pgDtE27R3OlD7e1vRmdpqZ7Rt+mCS2VxPRdaoqM7vCzPqaWbGZHZhyy/V6oNzMWj3mmNkUM/s3M+sD1BJth8R3MTCsa3v4zr+yxx8c/iN83g8SXUz+cyvTtLmPdxBvXlNSyJ5qonrXV8xsB1EymE/06xB3f5Dol8Y94RR5PtEFadx9E3AWcB3RxerJwL8SC3b3p4guBr9JVJ/6aIt1f57o4t9CortP/kJ0vSAd5xPVnS8mqkP9RljnHKILl78Oy1xCVHedjivC9C+Hz/o00S/kdFxKdPEwccfO3ex6W+81wB3hdP8zaSzvfGBFiOPLwOfamO62sL7nie6sqQW+lmbM6cb1S6ILzpuI9o8nOrH8PXEe0XWdzUTXaO6l7VulJxN9X9uJLlDf6O7PhYT9caLrIMuJPsOtRN8VvH/Q3Wxmr7Wy3D5E+/cmou92L6IzAoBvA+cS/Q/9NsS3J94j2mfXAX8EvhzO3HfRwT7eXrx5LXH3geQZM3uO6MLdrXHHEicz+wnRxdVZccfSU5jZvcBid8/4mUq2mdnxRP83YzuYtGDpTEHySqiGOyiczs8ELgIejDuufGZmh4cqxSIzOxk4nej6ihQgPdEs+WYgUZXRaKLqrOuJbpGUrtub6FrNMKJbnb/irTTVIYVB1UciIpKk6iMREUnK6+qj4cOHe3l5edxhiIjklblz525y9xGtjcvrpFBeXs6cOXPiDkNEJK+Y2cq2xqn6SEREkpQUREQkSUlBRESSlBRERCRJSUFERJKUFEREJElJQUREkvL6OQURkUJw9+xVVGzbuUvZfnsP5LSDur+zNyUFEZEctmLTDq564C0ALKW/udMOGq2kICJSaNaFM4SbPzedkw9Mt2+srsvYNQUzG2dmz5rZIjNbYGaXhfJrzGytmc0Lr1NT5rnKzJaY2dvpdM8oItLTvVdVC8CEYf07mLJ7ZPJMoRG43N1fC/32zjWzp8K4X7j7z1InNrMDgLOBaURt5T9tZvuFbv5ERArS1poGAAaWZqdiJ2NnCu5e4e6vhffVwCJgTDuznA7c4+517r6cqD/UmZmKT0QkHzQ3R33elPUtycr6snJLqpmVA4cCr4SiS83sTTO7zcyGhLIxwOqU2dbQShIxs4vNbI6Zzdm4cWMmwxYRiV1tQ1RZUlpSnJX1ZTwpmNkA4H7gG+5eBdwE7AMcAlQQdacIYK3Mvlu3cO5+i7vPcPcZI0a02hy4iEiPsbOhiV5FRklxdh4ry+hazKyEKCH80d0fAHD39e7e5O7NwG95v4poDTAuZfaxwLpMxicikutqG5rpm6WzBMjs3UcG/A5Y5O4/TylPvafqU8D88P4R4Gwz62NmE4HJwOxMxScikg8WrKukV3FrFSmZkcnL2ccA5wNvmdm8UPYd4BwzO4SoamgF8CUAd19gZvcBC4nuXLpEdx6JSKEb1LeEusbmrK0vY0nB3V+g9esEj7Uzz7XAtZmKSUQk39Q1NrPfyIFZW58axBMRyWF1DU306ZW9Q7WSgohIDqtrbKZPT7jQLCIie66usVlnCiIiEqlrbKK3koKIiADU60xBREQS1lfV0qeXrimIiAjQ0ORsr2vM2vqUFEREclSihdQJQ/tlbZ1KCiIiOaq2MWrUYUCW+lIAJQURkZxV2xA1b9EjGsQTEZE9szPZl4LuPhIRKXhVO6OuOLPVwQ4oKYiI5Kz60Dpqs+/W31jGKCmIiOSomvqo+mjkoNKsrVNJQUQkRyX6Z9aFZhERSZ4p9OutW1JFRAreis07AN19JCIiQEnom3lo/95ZW6eSgohIjtpeG7V51F/VRyIi8u6G7fQuLqKoqLXu7jNDSUFEJEdtqK6jV3H2EgIoKYiI5Kya+ibK+pZkdZ1KCiIiOaqypp6ZE4dmdZ1KCiIiOWpdZS2lWex1DZQURERyUkNT1O5RNvtSACUFEZGctLWmHoDxWex1DZQURERyUqLZ7GxTUhARyUEbq6MzhQnDdKYgIlLwNu+oA7LbGB4oKYiI5KREC6mjyrLXlwJkMCmY2Tgze9bMFpnZAjO7LJQPNbOnzOzd8HdIyjxXmdkSM3vbzD6aqdhERHLd/LWVAJT16zkPrzUCl7v7VOBI4BIzOwC4EnjG3ScDz4RhwrizgWnAycCNZpbdG3RFRHJEcWjvaFBpD0kK7l7h7q+F99XAImAMcDpwR5jsDuCT4f3pwD3uXufuy4ElwMxMxScikssWrK1idJarjiBL1xTMrBw4FHgFGOnuFRAlDmCvMNkYYHXKbGtCWctlXWxmc8xszsaNGzMat4hIXBqam2lyz/p6M54UzGwAcD/wDXevam/SVsp22yLufou7z3D3GSNGjOiuMEVEcsqS9duZvNfArK83o0nBzEqIEsIf3f2BULzezEaF8aOADaF8DTAuZfaxwLpMxicikstGDOyT9XVm8u4jA34HLHL3n6eMegSYFd7PAh5OKT/bzPqY2URgMjA7U/GJiOSqpmanuq6RcUP6Zn3dmXwq4hjgfOAtM5sXyr4DXAfcZ2YXAauAswDcfYGZ3QcsJLpz6RJ3b8pgfCIiOSnRDWd9U/avKWQsKbj7C7R+nQDghDbmuRa4NlMxiYjkg+q6qN2jScP7Z33deqJZRCTHbKiOmrjo3ye7TVxAJ5KCmWU/ZYmIFKBE9VFpSfZ/t3e4RjM72swWEj18hpkdbGY3ZjwyEZECtW7bTgDGZbkvBUjvTOEXwEeBzQDu/gZwXCaDEhEpZOurouqjof17Z33daZ2buPvqFkW6K0hEJEPqm6JD7LAYkkI6VzFWm9nRgJtZb+DrhKokERHpfgvXVdG/dzHR417Zlc6ZwpeBS4jaIVoDHBKGRUQkA/rGlBAgjTMFd98EnJeFWEREBNhe18Q+ew2IZd3p3H10h5kNThkeYma3ZTQqEZEClqg+ikM61UcHufu2xIC7byVqBltERDJgW009zTE0mw3pJYWiFl1mDiWzbSaJiBSsyp0NNDY7Y4dk/xkFSO/gfj3wopn9JQyfhdonEhHJiBWbdgDwwcnDY1l/Ohea7zSzucCHiRq4O8PdF2Y8MhGRApRo92hwv+w/owDpVwMtBrYmpjez8e6+KmNRiYgUqMUVUQeVcbSQCmkkBTP7GvADYD3Rk8xG1E3mQZkNTUSkcI0cVBrLetM5U7gMmOLumzMdjIhIodte10hJsdG7Vzw9G6Sz1tVAZaYDERERWPReNaW94nlGAdI7U1gGPGdmfwXqEoUt+l0WEZFusHl7HX1jenAN0ksKq8Krd3iJiEiGNDsM6lsS2/rTuSX1PyDqec3dd2Q+JBGRwrWhqpbj9hsR2/rTafvoKPW8JiKSeQ1NzWzeUU9JcTwtpEJ6F5p/iXpeExHJuPVVtQBMHB5PC6mgntdERHLGO+urARg7pG9sMajnNRGRHLFqcw0AU0cNjC0G9bwmIpIjlofG8OJqIRXU85qISM5YtmkH/XsXU1qSw88pmNnvido62oW7X5iRiEREClRdQzN9e8fbXU06a3805X0p8ClgXWbCEREpXK+t2soRk4bGGkM61Uf3pw6b2d3A0xmLSESkADU3e9Tj2uD4ridAmrektjAZGN/dgYiIFLL3wjMKI8viaTI7IZ0nmqvNrCrxF/g/4Io05rvNzDaY2fyUsmvMbK2ZzQuvU1PGXWVmS8zsbTP7aFc/kIhIPpq/NmqM+oAYb0eF9KqPuhrh7cCvgTtblP/C3X+WWmBmBwBnA9OA0cDTZrafu+shOREpCG+uiZLCtNFlscaRzt1H09sb7+6vtVH+vJmVpxnH6cA97l4HLDezJcBM4KU05xcRyWuLQjec44bGe00hnbuPbgSmA28SdcV5EPAK0EB0q+q/dXKdl5rZ54E5wOXuvpXowbiXU6ZZE8p2Y2YXAxcDjB+vSxsi0jPU1DfRP8Z+FBLSudC8AjjM3We4+2HAocASd/+wu3c2IdwE7EP0VHQFcH0ob61JwN2ejQBw91tCLDNGjIiveVkRke700rLNfGBsvFVHkF5S2N/d30oMuPt8ooN6p7n7endvcvdm4LdEVUQQnRmMS5l0LHoWQkQKRE19IwD77hVf66gJ6SSFRWZ2q5kdb2YfMrPf0sUG8cxsVMrgp4DEnUmPAGebWR8zm0h02+vsrqxDRCTfzFu1DYDJe8V75xGkd03hC8BXgMvC8PNE1UDtCg+5HQ8MN7M1wA+A483sEKKqoRXAlwDcfYGZ3QcsBBqBS3TnkYgUiqUbtwMwo3xIzJGkd0tqrZndDDzm7m+nu2B3P6eV4t+1M/21wLXpLl9EpKd4O/SjsM+IPKg+MrNPAPOAJ8LwIWb2SIbjEhEpGCs319C7uCjW1lET0rmm8AOiC8LbANx9HlCesYhERArMm2sqGTGwT9xhAOklhUZ3r8x4JCIiBWh9VS2VOxuYsnf8F5khvQvN883sXKDYzCYTdcf5YmbDEhEpDHNXbgXg9ENGxxxJJJ0zha8RtUlUB9wNVAHfyGBMIiIFY83WqF/mQ8YNjjeQIJ27j2qAq4GrzWwIsM3dW33aWEREOufJBesBGB9zm0cJbZ4pmNn3zWz/8L6Pmf0dWAKsN7MTsxWgiEhPtqiiioGlvTBrrbWf7Guv+uizQOK5hFlh2r2ADwE/znBcIiI9XlOzU1PfxMnT9o47lKT2kkJ9SjXRR4G7Q7tFi0jvArWIiLRj8XtRc9n75ECbRwntJYU6MzvQzEYAHwb+ljIuNyq/RETyWOJ6wvTx8TdvkdDeL/7LgL8AI4h6S1sOELrQfD0LsYmI9GhPLYySwowJeZAU3P0VYP9Wyh8DHstkUCIiPV1Ts7Oooooxg/tSVJQbF5khvecURESkm1VU7gRy56G1BCUFEZEYPLt4AwAH58hDawntPadwVvg7MXvhiIgUhicWvAfAkROHxRzJrto7U7gq/L0/G4GIiBSSF5duZsTAPpT1K4k7lF20d/fRZjN7FpjYWv8J7v6JzIUlItJzLdu4HXc4cepecYeym/aSwseA6cBdwPXZCUdEpOdLVB197AO5dZEZ2r8ltR542cyOdveNZjYwKvbt2QtPRKTnWVQRdb85c+LQmCPZXTp3H400s9eB+cBCM5trZgdmOC4RkR7rzTXbGNKvhN69cu8G0HQiugX4lrtPcPfxwOWhTEREOqm52Vm5uYapowbFHUqr0kkK/d392cSAuz8H9M9YRCIiPdjTi6KmLQ4dPzjeQNqQTmuny8zse0QXnAE+ByzPXEgiIj3XL59+F4DzjyyPN5A2pHOmcCFRo3gPhNdw4AuZDEpEpCeqrm1gYUUV44b2Ze+y0rjDaVU63XFuBb6ehVhERHq0h+atA+Di4/aJOZK25d6lbxGRHirRVPZZh42NOZK2KSmIiGTBzvomnn9nI717FVFaUhx3OG1SUhARyYJfPRNdYP7ah/eNOZL2dXhNIXTH+UWgPHV6d78wc2GJiPQs/3x3IwBfPj53rydAerekPgz8E3gaaMpsOCIiPU9DUzML1lUxZeRASopzu4ImnaTQz92v6OyCzew24DRgg7sfGMqGAvcSnXWsAD4T7m7CzK4CLiJKPF939yc7u04RkVz0ryWbADghB1tFbSmdlPWomZ3ahWXfDpzcouxK4Bl3nww8E4YxswOAs4FpYZ4bzSx3r8SIiHRC4oG1zx4+LuZIOtZez2vVZlYFXEaUGHaaWVVKebvc/XlgS4vi04E7wvs7gE+mlN/j7nXuvhxYAszs3EcREck9O+ubmLd6G8VFxoRhud9CUHtNZw/MwPpGuntFWH6FmSXOpcYAL6dMtyaU7cbMLgYuBhg/fnwGQhQR6T5/mbsagKtO2T/mSNLTYfWRmT2TTtkeslbKvLUJ3f0Wd5/h7jNGjBjRzWGIiHSv219cAcDnjpwQbyBpavNMwcxKiVpDHW5mQ3j/wD0I6Gp3QevNbFQ4SxgFbAjla4DUyraxwLourkNEJCc0NDWzdOMORpeV5vQDa6naO1P4EjAH2B94DZgbXg8DN3RxfY8As8L7WWFZifKzzayPmU0EJgOzu7gOEZGc8Ozi6HfvuUfkT1V3e9cUfgX8ysy+5u7/29kFm9ndwPFEZxprgB8A1wH3mdlFwCrgrLCuBWZ2H7AQaAQucXc9EyEiee2GZ5cAcMb03G3rqKV0nlNYa2ZntCirBN5y9w2tzQDg7ue0MeqENqa/Frg2jXhERHLe5u11vLGmkkGlvRg9uG/c4aQtnaRwEXAUkOh97XiiO4X2M7Mfuvtdbc0oIlKo/vPRhQBc/bGpMUfSOekkhWZgqruvBzCzkcBNwBHA87zfI5uIiAD1jc3JvhM+e3j+XE+A9J5oLk8khGADsJ+7bwEaMhOWiEj+uu7xxQB88YMTY46k89I5U/inmT0K/DkMfxp43sz6A9syFZiISD5yd277V9SN/eUnTYk5ms5LJylcQpQIjiF6VuFO4H53d+DDGYxNRCTv3P/aWgA+dtCovHk2IVU6fTQ78JfwEhGRNmyrqefbf34DgGs+Pi3maLomnWYuzjCzd82ssjMN4omIFJpL//Q6EF1LGDGwT8zRdE061Uc/BT7u7osyHYyISL5auK6KF0K/Cd85Nb9uQ02Vzt1H65UQRETa9/V7orOEuy6aiVlrbXzmh3TOFOaY2b3AQ0BdotDdH8hUUCIi+eSxtypYsmE7k0b054OT87v15nSSwiCgBjgppcwBJQURKXjuzlf/+BoAt806POZo9lw6dx99IRuBiIjkoz+8sgqAmROHUj4893tW60g6dx/tZ2bPmNn8MHyQmX0386GJiOS2nfVNfO+h+QDccO70mKPpHulcaP4tcBWhSQt3fxM4O5NBiYjkg7NveQmAC44uz9tbUFtKJyn0c/eWHd40ZiIYEZF88eDra3hjTSWQfy2htiedpLDJzPYh9JlsZmcCFRmNSkQkh63eUsM3742eXH7wq0dTUpzOoTQ/pNv20S3A/ma2FlgOnJfRqEREclRzs3Pa/74AwH+d8QEOHT8k5oi6V4fpzd2XufuJwAhgf3c/FvhUxiMTEckx7s6/3zmHyp0NlA/rxzkz86uvhHSkfc7j7jvcvToMfitD8YiI5KzfPL+Mvy+OeiF++JJjY44mM7paEZa/z3CLiHTBM4vWJzvP+cf/O56yfiUxR5QZXU0K3q1RiIjksBeXbOKiO+YAUdtGE4bl/0NqbWnzQrOZVdP6wd+AvhmLSEQkh8xduYVzb30FgO9+bGret23UkTaTgrsPzGYgIiK5Zv7aSj59U/SA2pWn7M+/f3BSzBFlXjq3pIqIFJx31lcnbz396ZkH8ZkZ42KOKDuUFEREUjQ3O08seC/Z8unFx00qmIQASgoiIkmbt9dx8V1zmbtyKwBnHz6Oq07ZP+aosktJQUQKnrvz0tLNyQvK/XoX8+BXj2HK3oV3aVVJQUQKWuXOBi68/dXk2cGsoyZwzSem5XWXmntCSUFECtbLyzbz+d/Npr6pmV5Fxm/OP4wTpo6MO6xYKSmISMGpb2zmB4/M5+7ZqwE4eGwZd154RI99SrkzYkkKZrYCqAaagEZ3n2FmQ4F7gXJgBfAZd98aR3wi0jNt3VHPPa+u5idPLE6W/e85h3LaQaMKtrqopTjPFD7s7ptShq8EnnH368zsyjB8RTyhiUhPsmZrDQ/PW8d/P/l2suyiYyfyrY/sR/8+qjBJlUtb43Tg+PD+DuA5lBREZA/sqGvkpueW8utnlyTLvvyhffj4waOYNrosxshyV1xJwYG/mZkDv3H3W4CR7l4B4O4VZrZXazOa2cXAxQDjx/e8tsxFZM81Nzvfum8ej7yxjubQgtuZh43l8pP2Y1SZmm5rT1xJ4Rh3XxcO/E+Z2eIO5whCArkFYMaMGWqtVUQAqKptYNnGHXzh97PZWtOQLD/j0DH85MyDelSXmZkUS1Jw93Xh7wYzexCYCaw3s1HhLGEUsCGO2EQkv8xfW8mrK7Zw7V8X0RhOC8YP7cdnZozl/KPKKeurO4o6I+tJwcz6A0XuXh3enwT8EHgEmAVcF/4+nO3YRCR//PGVlbyybAuPvLEuWXbw2DIuP2kKR0waSp9exTFGl7/iOFMYCTwYbv/qBfzJ3Z8ws1eB+8zsImAVcFYMsYlIjmludrbU1APwk8cX89KyzZjB6i07AZg4vD/nzhzPWTPGUta3RLeW7qGsJwV3XwYc3Er5ZuCEbMcjIrmnqdl5cekmahuauf5vb7P4vepdxp9x6BhmlhtfOKacA8foLqLulEu3pIpIAXvw9TW8u347AC8s2cSbayqT40pLirj61KlgxolT99IdRBmkpCAisZi/tpKfPLGYxiansbmZV1dEDRiUFBvNDn1LirnropmUlhQzcXh/PWSWJdrKIpIxTc3O0o3baQp3BV12z+us2FxDkUFtQzMAh00YQrEZR+8zjO9+7AAOGD0ozpALnpKCiHSbhqZmHn1zHTvrowP+3bNX8dbayl2mKetbwtmHRz2ZTdl7IGdMH5v1OKVtSgoi0mVLNlRz6z+XJ88EXl6+OXlXUKqbPzcdgCIzjt53OANUFZSz9M2ISJsampqpbWgCYGN1HZf+6XXqm5qT45dsiC4MjyorxYjar5m81wBunTWD0pLoOYGyviXJ95L7lBREJOnd9dVUVNYC0OzOBb9/dbdppo4axKTh/QGYMnIgh4wbzBePm5TVOCVzlBREClRtQxN3vrQiWf9f19jEjc8t3W266eMHc+oHRgEwuF9vPj19jB4Q68GUFEQKQHOz872H57N22/v1/XNXbqW6tnG3ab/1kf04Zt9hAJQUFzFtdBnFRUoChUJJQaQHqKjcyc76puTwQ/PWcceLK5LDlTvfbzX04LHRE8CThvdn2IA+3HjedHqntCBapARQ0JQURPLM7OVbWL2lJjk8Z+VW7p69qtVpLzi6PPm+T68ivnL8Pgzu1zvTIUoeU1IQyWFrttZw6z+X09gc1fvvrG/m/tfWtDrtf3xiGoNTOp7ff+9BTNl7YFbilJ5DSUEkRk3NnrzHH+Cpheu56R9L8FC0YF0VAIP7lVBshgPD+vfme6cdwPTxQ5LzDerbS2cA0i2UFESyZGN1Hcs2bk8O1zQ08YVWbvkEOHFq1BvtqLJSpo4axOUnTclKjCJKCiIZsL2ukfteXb3Lg17XPd56r7NHTRrGsZOHJ4enjx/CUfsMy3iMIq1RUhDZQ6s21/DTJxfTkJIA/vHOxmSDb6lOnDqSC48pTw73KSnm0HGDdceP5AwlBZE2VNU27HYf/y+eeod/vLOR1EP4huo6AMqH9Us251A+rD97l5Vyw7nTKQoPepmh5h4k5ykpSEFzd/7xzka21+168K/c2cDVD85vc75zZo7bZXjS8AFq6kF6BCUFKQh1jU3c8OxSdrQ4+C9YV8nLy7a0Od+np4/liIlDdyk7dvJwRg9Wz1/SMykpSI+yZUc9l93z+m4H/0UV1ewMrX2mNtvs7gzs04tbPj+D4QN2vaWztKSYcUP7ZT5okRyipCA5bUNVLetCq52plm/azjfvfQOI6uoTEvf3jx3Sl4mhJU+AGeVDKOtbwn+feTB9e6teX6QtSgoSO3fnoXlr2VbT0KIcfvjownbnPePQMYwdsmtVzuB+vbng6HLd0SPSBUoKkjWLKqq45flluzzBC7B04/bkk7ut+eQhozn9kDG7lQ/uV8KhKU/1isieU1KQLmludrbU1O9WXtvQxBfvnEt1bQMtm9xPdNOYWq2TsN/IAdxw7nRGDOyzS3lRkTGotGS36UUkM5QUpFW1DU28tHQzjS1+1Sf87Mm3eXt9dZvzjxncl5nlu961c/gEOHTCEM4/ckK3xioi3UdJoYDNX1vJY29VtDruodfXtnqBN1XfkmK+c+r+u5WXlhRz+iFj6N2rqJW5RCSXKSn0YAvWVXLd44t3q8NPeHHpZgBKine/INvssPegUm6dNaPN5U8c3p/+fbQLifQk+o/OQeu27aSqtqHN8TX1Tcy6bTb1jc3JJhRak7gvf/r4wa12p3h4+RA+cfBozj+qfI9jFpGeQUkhS9ydJ+a/x7adbR/sASoqa/mfZ95Na5kfGFPWYWuaU0YO5NOHjU07ThEpbEoKnfTE/Ar+vnhDp+dbvmkHr67Ymvb0Xz9hMlPb6TWrtHcxx00eoQ7VRaRb5VxSMLOTgV8BxcCt7n5dd69j8XtVfO1Pr3dp3nc3RJ2kjCor7dR87tEdOTecN529B7U/b2lJkXrREpFY5FRSMLNi4AbgI8Aa4FUze8Td23+stZNKexUzeeSALs07eeQAzjtiAsfsO7zjiUVE8kxOJQVgJrDE3ZcBmNk9wOlAtyaF8uH9ufG8w7pzkSIiPUKu3Ug+BlidMrwmlCWZ2cVmNsfM5mzcuDGrwYmI9HS5lhRau2q6y0327n6Lu89w9xkjRozIUlgiIoUh15LCGiC1S6uxwLqYYhERKTi5lhReBSab2UQz6w2cDTwSc0wiIgUjpy40u3ujmV0KPEl0S+pt7r4g5rBERApGTiUFAHd/DHgs7jhERApRrlUfiYhIjJQUREQkydxbb1Y5H5jZRmDlHixiOLCpm8LpqbSN0qPt1DFto/RkYztNcPdW7+nP66Swp8xsjru33WGAaBulSdupY9pG6Yl7O6n6SEREkpQUREQkqdCTwi1xB5AHtI3So+3UMW2j9MS6nQr6moKIiOyq0M8UREQkhZKCiIgkFWRSMLOTzextM1tiZlfGHU+2mdkKM3vLzOaZ2ZxQNtTMnjKzd8PfISnTXxW21dtm9tGU8sPCcpaY2f+YWV53GG1mt5nZBjObn1LWbdvFzPqY2b2h/BUzK8/qB+wGbWyja8xsbdif5pnZqSnjCnEbjTOzZ81skZktMLPLQnl+7EvuXlAvoob2lgKTgN7AG8ABcceV5W2wAhjeouynwJXh/ZXAT8L7A8I26gNMDNuuOIybDRxF1A/G48ApcX+2PdwuxwHTgfmZ2C7AV4Gbw/uzgXvj/szdtI2uAb7dyrSFuo1GAdPD+4HAO2Fb5MW+VIhnCskuP929Hkh0+VnoTgfuCO/vAD6ZUn6Pu9e5+3JgCTDTzEYBg9z9JY/2zDtT5slL7v48sKVFcXdul9Rl/QU4Id/OrtrYRm0p1G1U4e6vhffVwCKiHiTzYl8qxKTQYZefBcCBv5nZXDO7OJSNdPcKiHZqYK9Q3tb2GhPetyzvabpzuyTncfdGoBIYlrHIs+tSM3szVC8lqkUKfhuFap1DgVfIk32pEJNCh11+FoBj3H06cApwiZkd1860bW2vQt+OXdkuPXWb3QTsAxwCVADXh/KC3kZmNgC4H/iGu1e1N2krZbFtp0JMCgXf5ae7rwt/NwAPElWprQ+nq4S/G8LkbW2vNeF9y/Kepju3S3IeM+sFlJF+VUzOcvf17t7k7s3Ab4n2JyjgbWRmJUQJ4Y/u/kAozot9qRCTQkF3+Wlm/c1sYOI9cBIwn2gbzAqTzQIeDu8fAc4OdztMBCYDs8Ppb7WZHRnqMj+fMk9P0p3bJXVZZwJ/D3XFeS1xoAs+RbQ/QYFuo/CZfgcscvefp4zKj30p7iv1cbyAU4nuCFgKXB13PFn+7JOI7nR4A1iQ+PxE9ZHPAO+Gv0NT5rk6bKu3SbnDCJhBdABYCvya8IR8vr6Au4mqPxqIfold1J3bBSgF/kx0IXE2MCnuz9xN2+gu4C3gTaKD1agC30bHElXlvAnMC69T82VfUjMXIiKSVIjVRyIi0gYlBRERSVJSEBGRJCUFERFJUlIQEZEkJQXJa2Z2dWiJ8s3QQucRGV7fc2aWdqfqZnZ7aEG0TxgebmYruimW483s0e5YlkiCkoLkLTM7CjiNqEXKg4AT2bUNmVzRBFwYdxAtmVlx3DFI7lFSkHw2Ctjk7nUA7r7JQxMeZvZ9M3vVzOab2S0p7dA/Z2a/MLPnQ3v3h5vZA6GN+x+FacrNbLGZ3RHOQP5iZv1artzMTjKzl8zsNTP7c2jrpjW/BL4ZmiNInX+XX/pm9mszuyC8X2FmPw7Ln2Nm083sSTNbamZfTlnMIDN70MwWmtnNZlbUXmxhud83sxeAs7qwzaWHU1KQfPY3YJyZvWNmN5rZh1LG/drdD3f3A4G+RGcUCfXufhxwM1GzAZcABwIXmFmipckpwC3hDKSKqP36JDMbDnwXONGjxgXnAN9qI85VwAvA+Z38fKvd/Sjgn8DtRM0ZHAn8MGWamcDlwAeIGqU7I43Yat39WHe/p5PxSAFQUpC85e7bgcOAi4GNwL2JX9rAhy3qkeot4N+AaSmzJtq6egtY4FH793XAMt5vmGy1u/8rvP8DUdMFqY4k6hzlX2Y2j6gdmgnthPtj4P/Ruf+51Dhfcfdqd98I1JrZ4DButkd9gzQRNUFxbBqx3duJGKTA9Op4EpHcFQ6GzwHPhQQwy8zuAW4EZrj7ajO7hqitmIS68Lc55X1iOPE/0bL9l5bDBjzl7uekGeeScID+TEpxI7smiVJ21dU4O4ptRzoxS2HSmYLkLTObYmaTU4oOAVby/sF1U6hLP7MLix8fLmQDnENU/ZPqZeAYM9s3xNLPzPbrYJnXAt9OGV4JHBBaxywDTuhCnDNDi79FwGdDnF2JTQRQUpD8NgC4I1xkfZOoyuQad99G1K7/W8BDRM2ld9YiorOON4GhRB3JJIVqnAuAu8M0LwP7t7dAd18AvJYyvBq4j6g1zT8Cr3chzpeA64ha0lwOPNiV2EQS1EqqSAsWdaH4aLhILVJQdKYgIiJJOlMQEZEknSmIiEiSkoKIiCQpKYiISJKSgoiIJCkpiIhI0v8HpbqfTgujFSMAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Get the new list of lengths after sorting.\n",
        "sorted_lengths = [len(s[0]) for s in train_samples]\n",
        "\n",
        "# Plot the sequence lengths for visualization.\n",
        "plt.plot(range(0, len(sorted_lengths)), sorted_lengths)\n",
        "plt.xlabel('Sample Number')\n",
        "plt.ylabel('Length of Sequence')\n",
        "plt.title('Sequence lengths of training set samples')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "pB_4WQG7C-cQ"
      },
      "outputs": [],
      "source": [
        "def create_smart_padded_batches(text_samples, labels, batch_size, max_len = 256):\n",
        "    print('Forming smart batches from {} examples. Batch size {}\\n'.format(len(text_samples), batch_size))\n",
        "    # ------------------------------------------------------------------\n",
        "    # First tokenize all the samples and truncate them to a max length.\n",
        "    # ------------------------------------------------------------------\n",
        "    tokenized_inputs = []\n",
        "    for sample in tqdm(text_samples):\n",
        "        # Tokenize the sample\n",
        "        tokenized_input = tokenizer.encode(text=sample,\n",
        "                                     add_special_tokens=True,\n",
        "                                     max_length=max_len,\n",
        "                                     truncation=True,\n",
        "                                     padding=False)\n",
        "        # Add to list\n",
        "        tokenized_inputs.append(tokenized_input)\n",
        "    print('Finished tokenizing: {:>10,} samples\\n'.format(len(tokenized_inputs)))\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # Batch the tokenized sequences together after sorting them by length.\n",
        "    # ---------------------------------------------------------------------\n",
        "    sorted_samples_labels = sorted(zip(tokenized_inputs, labels), key=lambda x: len(x[0]))\n",
        "\n",
        "    # Create lists of batches of samples and labels.\n",
        "    batch_ordered_sentences = []\n",
        "    batch_ordered_labels = []\n",
        "\n",
        "    # Loop over the input samples until it is empty\n",
        "    while len(sorted_samples_labels) > 0:\n",
        "        # Print progress after 500 batches.\n",
        "        if ((len(batch_ordered_sentences) % 500) == 0):\n",
        "            print(' Finished {:,} batches.'.format(len(batch_ordered_sentences)))\n",
        "\n",
        "        # num_samples_to_pick = normally batch size, for the last batch it will be the remaining samples\n",
        "        num_samples_to_pick = min(batch_size, len(sorted_samples_labels))\n",
        "\n",
        "        # Start at a random point in the list of samples and choose num_samples_to_pick contiguous samples\n",
        "        start = random.randint(0, len(sorted_samples_labels) - num_samples_to_pick)\n",
        "        batch = sorted_samples_labels[start:start + num_samples_to_pick]\n",
        "\n",
        "        # Split the (samples, labels) tuples into samples and labels\n",
        "        batch_ordered_sentences.append([s[0] for s in batch])\n",
        "        batch_ordered_labels.append([s[1] for s in batch])\n",
        "\n",
        "        # Remove these samples from the original list of training samples.\n",
        "        del sorted_samples_labels[start:start + num_samples_to_pick]\n",
        "    print('\\n  Finished processing {:,} batches.'.format(len(batch_ordered_sentences)))\n",
        "\n",
        "    # --------------\n",
        "    #  Add Padding\n",
        "    # --------------\n",
        "    py_inputs = []\n",
        "    py_attn_masks = []\n",
        "    py_labels = []\n",
        "\n",
        "    # For each batch...\n",
        "    for (batch_inputs, batch_labels) in zip(batch_ordered_sentences, batch_ordered_labels):\n",
        "        # Lists of padded inputs and masks\n",
        "        batch_padded_inputs = []\n",
        "        batch_attn_masks = []\n",
        "\n",
        "        # Get the longest sequence size in the current batch\n",
        "        max_size = max([len(sen) for sen in batch_inputs])\n",
        "\n",
        "        # Pad the sequences uptp the max_size and also create the attention masks.\n",
        "        for sen in batch_inputs:\n",
        "            padding_count = max_size - len(sen)\n",
        "            # Add the token for padding at the end of the sequence.\n",
        "            padded_input = sen + [tokenizer.pad_token_id]*padding_count\n",
        "            # Create the attention mask with 1 for real tokens and 0 for padding tokens.\n",
        "            attn_mask = [1] * len(sen) + [0] * padding_count\n",
        "            # Add these to the lists.\n",
        "            batch_padded_inputs.append(padded_input)\n",
        "            batch_attn_masks.append(attn_mask)\n",
        "\n",
        "        # Convert to tensors and add to the lists.\n",
        "        py_inputs.append(torch.tensor(batch_padded_inputs))\n",
        "        py_attn_masks.append(torch.tensor(batch_attn_masks))\n",
        "        py_labels.append(torch.tensor(batch_labels))\n",
        "\n",
        "    print('Finished Padding.')\n",
        "    token_count_padded = 0\n",
        "    for batch in py_inputs:\n",
        "        for sen in batch:\n",
        "            token_count_padded += len(sen)\n",
        "    token_count_fixed = max_len * len(py_inputs) * batch_size\n",
        "    print('  Number of tokens with fixed padding: {}'.format(token_count_fixed))\n",
        "    print('  Number of tokens with smart padding: {}'.format(token_count_padded))\n",
        "    print('  Percentage reduction in tokens is: {:,.2f}%'.format(100*(token_count_fixed-token_count_padded)/token_count_fixed))\n",
        "\n",
        "    # Return the dataset\n",
        "    return (py_inputs, py_attn_masks, py_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "oTvV9Jz9C-cQ"
      },
      "outputs": [],
      "source": [
        "def format_time(elapsed):\n",
        "    # Return time as string hh:mm:ss\n",
        "    time_int = int(round((elapsed)))\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=time_int))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "8987905efaff45c39188a0b543fa2343",
            "689ac92d11414ef29068fcebd1ec1b89",
            "219eff0d81a3479187a4674b58d77461",
            "de54a24e5f8b4c3780146a5f65cb3ac9",
            "01d433b5612f4925869fcacb1aafed11",
            "49d6048613e54a399c342da92c557974",
            "e1f87b7f4d9e449796b257a5a48ef6c4",
            "d525b9bcdb4546b699981ca411c03054",
            "25a87c2c0dea4cfc839252e976d1da24",
            "613c38b31e1343b3a9aa55893309beaa",
            "36e818783c3643df885912802367e7c1"
          ]
        },
        "id": "2XM37Zr4C-cQ",
        "outputId": "5aa0df50-404c-4985-95ed-971f8390db2c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config: <class 'transformers.models.bert.configuration_bert.BertConfig'> \n",
            "\n",
            "Model type: <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'>\n",
            "DONE.\n"
          ]
        }
      ],
      "source": [
        "# Create config and network for multiclass sequence classification.\n",
        "config = AutoConfig.from_pretrained(pretrained_model_name_or_path='bert-base-uncased',\n",
        "                                    num_labels=3)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    pretrained_model_name_or_path='bert-base-uncased',\n",
        "    config=config)\n",
        "\n",
        "print('Config:', str(type(config)), '\\n')\n",
        "print('Model type:', str(type(model)))\n",
        "\n",
        "# Load the model on the GPU\n",
        "device = torch.device('cpu')\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "desc = model.to(device)\n",
        "print('DONE.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a22bR701C-cR",
        "outputId": "3f1e633c-62a6-423d-e9f6-1353793949d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Forming smart batches from 20700 examples. Batch size 8\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20700/20700 [00:07<00:00, 2625.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished tokenizing:     20,700 samples\n",
            "\n",
            " Finished 0 batches.\n",
            " Finished 500 batches.\n",
            " Finished 1,000 batches.\n",
            " Finished 1,500 batches.\n",
            " Finished 2,000 batches.\n",
            " Finished 2,500 batches.\n",
            "\n",
            "  Finished processing 2,588 batches.\n",
            "Finished Padding.\n",
            "  Number of tokens with fixed padding: 5300224\n",
            "  Number of tokens with smart padding: 735624\n",
            "  Percentage reduction in tokens is: 86.12%\n"
          ]
        }
      ],
      "source": [
        "# Define the optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = 2e-6, eps = 1e-8)\n",
        "\n",
        "batch_size = 8\n",
        "epochs = 4\n",
        "\n",
        "# Max length for tokenization\n",
        "max_len = 256\n",
        "\n",
        "# Perform tokenization and smart batching on the training data\n",
        "(py_inputs, py_attn_masks, py_labels) = create_smart_padded_batches(X_train_nn, y_train, batch_size, max_len)\n",
        "total_steps = len(py_inputs) * epochs   # training_steps = [number of batches] x [number of epochs].\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8BoqysmC-cR",
        "outputId": "5af4dfca-ea68-42a3-a4a4-e02dbfb64aba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 1 / 4 ===\n",
            "Training on 2588 batches...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2588/2588 [05:01<00:00,  8.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.82\n",
            "  Training epcoh took: 0:05:02\n",
            "\n",
            "Running Validation...\n",
            "Forming smart batches from 6900 examples. Batch size 8\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6900/6900 [00:03<00:00, 2182.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished tokenizing:      6,900 samples\n",
            "\n",
            " Finished 0 batches.\n",
            " Finished 500 batches.\n",
            "\n",
            "  Finished processing 863 batches.\n",
            "Finished Padding.\n",
            "  Number of tokens with fixed padding: 1767424\n",
            "  Number of tokens with smart padding: 250064\n",
            "  Percentage reduction in tokens is: 85.85%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 1/4 [05:22<16:07, 322.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 2 / 4 ===\n",
            "Forming smart batches from 20700 examples. Batch size 8\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20700/20700 [00:09<00:00, 2169.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished tokenizing:     20,700 samples\n",
            "\n",
            " Finished 0 batches.\n",
            " Finished 500 batches.\n",
            " Finished 1,000 batches.\n",
            " Finished 1,500 batches.\n",
            " Finished 2,000 batches.\n",
            " Finished 2,500 batches.\n",
            "\n",
            "  Finished processing 2,588 batches.\n",
            "Finished Padding.\n",
            "  Number of tokens with fixed padding: 5300224\n",
            "  Number of tokens with smart padding: 735128\n",
            "  Percentage reduction in tokens is: 86.13%\n",
            "Training on 2588 batches...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2588/2588 [05:07<00:00,  8.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.68\n",
            "  Training epcoh took: 0:05:08\n",
            "\n",
            "Running Validation...\n",
            "Forming smart batches from 6900 examples. Batch size 8\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6900/6900 [00:03<00:00, 1898.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished tokenizing:      6,900 samples\n",
            "\n",
            " Finished 0 batches.\n",
            " Finished 500 batches.\n",
            "\n",
            "  Finished processing 863 batches.\n",
            "Finished Padding.\n",
            "  Number of tokens with fixed padding: 1767424\n",
            "  Number of tokens with smart padding: 247536\n",
            "  Percentage reduction in tokens is: 85.99%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 2/4 [11:01<11:04, 332.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 3 / 4 ===\n",
            "Forming smart batches from 20700 examples. Batch size 8\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20700/20700 [00:11<00:00, 1847.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished tokenizing:     20,700 samples\n",
            "\n",
            " Finished 0 batches.\n",
            " Finished 500 batches.\n",
            " Finished 1,000 batches.\n",
            " Finished 1,500 batches.\n",
            " Finished 2,000 batches.\n",
            " Finished 2,500 batches.\n",
            "\n",
            "  Finished processing 2,588 batches.\n",
            "Finished Padding.\n",
            "  Number of tokens with fixed padding: 5300224\n",
            "  Number of tokens with smart padding: 736120\n",
            "  Percentage reduction in tokens is: 86.11%\n",
            "Training on 2588 batches...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2588/2588 [05:11<00:00,  8.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.64\n",
            "  Training epcoh took: 0:05:11\n",
            "\n",
            "Running Validation...\n",
            "Forming smart batches from 6900 examples. Batch size 8\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6900/6900 [00:03<00:00, 1935.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished tokenizing:      6,900 samples\n",
            "\n",
            " Finished 0 batches.\n",
            " Finished 500 batches.\n",
            "\n",
            "  Finished processing 863 batches.\n",
            "Finished Padding.\n",
            "  Number of tokens with fixed padding: 1767424\n",
            "  Number of tokens with smart padding: 247488\n",
            "  Percentage reduction in tokens is: 86.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 3/4 [16:46<05:38, 338.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 4 / 4 ===\n",
            "Forming smart batches from 20700 examples. Batch size 8\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20700/20700 [00:10<00:00, 1960.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished tokenizing:     20,700 samples\n",
            "\n",
            " Finished 0 batches.\n",
            " Finished 500 batches.\n",
            " Finished 1,000 batches.\n",
            " Finished 1,500 batches.\n",
            " Finished 2,000 batches.\n",
            " Finished 2,500 batches.\n",
            "\n",
            "  Finished processing 2,588 batches.\n",
            "Finished Padding.\n",
            "  Number of tokens with fixed padding: 5300224\n",
            "  Number of tokens with smart padding: 736600\n",
            "  Percentage reduction in tokens is: 86.10%\n",
            "Training on 2588 batches...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2588/2588 [05:07<00:00,  8.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.63\n",
            "  Training epcoh took: 0:05:08\n",
            "\n",
            "Running Validation...\n",
            "Forming smart batches from 6900 examples. Batch size 8\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6900/6900 [00:03<00:00, 1812.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished tokenizing:      6,900 samples\n",
            "\n",
            " Finished 0 batches.\n",
            " Finished 500 batches.\n",
            "\n",
            "  Finished processing 863 batches.\n",
            "Finished Padding.\n",
            "  Number of tokens with fixed padding: 1767424\n",
            "  Number of tokens with smart padding: 248156\n",
            "  Percentage reduction in tokens is: 85.96%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [22:27<00:00, 336.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training complete!\n",
            "Total training took 0:22:27 (h:mm:ss)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from functools import partial\n",
        "from tqdm import tqdm\n",
        "tqdm = partial(tqdm, position=0, leave=True)\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 87\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in tqdm(range(0, epochs)):\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    print('\\n=== Epoch {:} / {:} ==='.format(epoch_i + 1, epochs))\n",
        "\n",
        "    # Randomnize the training set, i.e smart batch again\n",
        "    if epoch_i > 0:\n",
        "        (py_inputs, py_attn_masks, py_labels) = create_smart_padded_batches(X_train_nn, y_train, batch_size, max_len)\n",
        "    print('Training on {:} batches...'.format(len(py_inputs)))\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step in tqdm(range(0, len(py_inputs))):\n",
        "        # Copy the current training batch to the GPU.\n",
        "        batch_input_ids = py_inputs[step].to(device)\n",
        "        batch_input_mask = py_attn_masks[step].to(device)\n",
        "        batch_labels = py_labels[step].to(device)\n",
        "\n",
        "        # Clear gradients\n",
        "        model.zero_grad()\n",
        "        # Forward pass\n",
        "        result = model(\n",
        "            batch_input_ids,\n",
        "            token_type_ids=None,\n",
        "            attention_mask=batch_input_mask,\n",
        "            labels=batch_labels)\n",
        "\n",
        "        # Compute training loss and accumulate\n",
        "        loss = result.loss\n",
        "        total_train_loss += loss.item()\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # To prevent exploding gradinets problem, clip the norm of the gradients to 1.0.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update the parameters and the learning rate.\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "    # Calculate the average training loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(py_inputs)\n",
        "\n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - start_time)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    print(\"\\nRunning Validation...\")\n",
        "    (py_val_inputs, py_val_attn_masks, py_val_labels) = create_smart_padded_batches(X_val_nn, y_val, batch_size, max_len)\n",
        "\n",
        "    # Tracking variables\n",
        "    predictions , true_labels = [], []\n",
        "\n",
        "    # model.eval()\n",
        "    total_val_loss = 0\n",
        "    # For each batch of validation\n",
        "    for step in range(0, len(py_val_inputs)):\n",
        "        # Copy the batch to the GPU.\n",
        "        batch_input_ids_val = py_val_inputs[step].to(device)\n",
        "        batch_input_mask_val = py_val_attn_masks[step].to(device)\n",
        "        batch_labels_val = py_val_labels[step].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Forward pass, calculate logit predictions\n",
        "            outputs = model(batch_input_ids_val, token_type_ids=None,\n",
        "                            attention_mask=batch_input_mask_val, labels=batch_labels_val)\n",
        "        total_val_loss += outputs.loss\n",
        "        logits = outputs.logits\n",
        "        # compute validation loss\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = batch_labels_val.to('cpu').numpy()\n",
        "\n",
        "        # Store predictions and true labels\n",
        "        predictions.append(logits)\n",
        "        true_labels.append(label_ids)\n",
        "\n",
        "    # Combine the results across the batches.\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "    # Choose the label with the highest score as our prediction.\n",
        "    preds = np.argmax(predictions, axis=1).flatten()\n",
        "\n",
        "    f1 = f1_score(true_labels, preds, average='macro')\n",
        "    # Calculate the average val loss over all of the batches.\n",
        "    avg_val_loss = total_val_loss / len(py_val_inputs)\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Training Time': training_time,\n",
        "            'validation loss': avg_val_loss,\n",
        "            'validation F1 score': f1\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aK_-AfHLIRjB",
        "outputId": "9fc08ecd-68e0-475b-b6fa-ddb88efca4c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'epoch': 1,\n",
              "  'Training Loss': 0.8171782934522887,\n",
              "  'Training Time': '0:05:02',\n",
              "  'validation loss': tensor(0.7340, device='cuda:0'),\n",
              "  'validation F1 score': 0.6780297446035916},\n",
              " {'epoch': 2,\n",
              "  'Training Loss': 0.6830918176741652,\n",
              "  'Training Time': '0:05:08',\n",
              "  'validation loss': tensor(0.7037, device='cuda:0'),\n",
              "  'validation F1 score': 0.6930339363610306},\n",
              " {'epoch': 3,\n",
              "  'Training Loss': 0.6438738309232722,\n",
              "  'Training Time': '0:05:11',\n",
              "  'validation loss': tensor(0.6955, device='cuda:0'),\n",
              "  'validation F1 score': 0.6957078817369213},\n",
              " {'epoch': 4,\n",
              "  'Training Loss': 0.625170377473213,\n",
              "  'Training Time': '0:05:08',\n",
              "  'validation loss': tensor(0.6922, device='cuda:0'),\n",
              "  'validation F1 score': 0.6994341574811945}]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By checking the validation loss, we stop the training here to avoid overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFi-vCkEC-cR",
        "outputId": "e7c4b7f5-3533-40fa-9946-527a442a4377"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Forming smart batches from 6900 examples. Batch size 8\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6900/6900 [00:03<00:00, 2055.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished tokenizing:      6,900 samples\n",
            "\n",
            " Finished 0 batches.\n",
            " Finished 500 batches.\n",
            "\n",
            "  Finished processing 863 batches.\n",
            "Finished Padding.\n",
            "  Number of tokens with fixed padding: 1767424\n",
            "  Number of tokens with smart padding: 240088\n",
            "  Percentage reduction in tokens is: 86.42%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on the test split\n",
        "(py_test_inputs, py_test_attn_masks, py_test_labels) = create_smart_padded_batches(X_test_nn, y_test, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_rHU1MFC-cS",
        "outputId": "cbac6109-420d-4a31-ae61-41c404db1201"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting labels for 863 test batches ...\n",
            "    DONE.\n",
            "Accuracy: 0.716\n",
            "F1 score: 0.715\n"
          ]
        }
      ],
      "source": [
        "# Prediction on test set with the best model\n",
        "print('Predicting labels for {:,} test batches ...'.format(len(py_test_labels)))\n",
        "model.eval()\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# For each batch of test\n",
        "for step in range(0, len(py_test_inputs)):\n",
        "    # Copy the batch to the GPU.\n",
        "    b_input_ids = py_test_inputs[step].to(device)\n",
        "    b_input_mask = py_test_attn_masks[step].to(device)\n",
        "    b_labels = py_test_labels[step].to(device)\n",
        "\n",
        "    # Telling the model not to compute or store gradients, saving memory and\n",
        "    # speeding up prediction\n",
        "    with torch.no_grad():\n",
        "        # Forward pass, calculate logit predictions\n",
        "        outputs = model(b_input_ids, token_type_ids=None,\n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Store predictions and true labels\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')\n",
        "\n",
        "# Combine the results across the batches.\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Choose the label with the highest score as our prediction.\n",
        "preds = np.argmax(predictions, axis=1).flatten()\n",
        "\n",
        "# Calculate simple flat accuracy -- number correct over total number.\n",
        "accuracy = (preds == true_labels).mean()\n",
        "\n",
        "print('Accuracy: {:.3f}'.format(accuracy))\n",
        "from sklearn.metrics import f1_score\n",
        "f1 = f1_score(true_labels, preds, average='macro')\n",
        "print('F1 score: {:.3f}'.format(f1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Saving the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzVwA3fVBfh9",
        "outputId": "89cf01df-7170-48ff-edf1-3211fb492d76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('bert_tokenizer\\\\tokenizer_config.json',\n",
              " 'bert_tokenizer\\\\special_tokens_map.json',\n",
              " 'bert_tokenizer\\\\vocab.txt',\n",
              " 'bert_tokenizer\\\\added_tokens.json')"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the model and tokenizer - This is the best model\n",
        "model.save_pretrained(\"bert_model\")\n",
        "tokenizer.save_pretrained(\"bert_tokenizer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Final prediction\n",
        "Predicting on the outputs of the different chatbot LLMs\n",
        "Treating BERT predictions as ground truth labels and the tones predicted by the chatbot LLMs as the predicted labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "C-Vc9VS0GWrK"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Load the model and tokenizer from the saved directory\n",
        "model_name = \"bert-base-uncased\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert_model/\")\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)  # Move the model to the same device as input tensors\n",
        "\n",
        "# set model to evaluate mode\n",
        "model.eval()\n",
        "\n",
        "# Load the tokenizer from the saved directory\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert_tokenizer/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYYIbOGVSESY",
        "outputId": "e81eec81-ad4e-46e2-a825-6c2c9a70c547"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting for chatbot: gpt\n",
            "Finished tokenizing:          3 samples\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  5.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting for chatbot: gptlc\n",
            "Finished tokenizing:          3 samples\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 49.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting for chatbot: alpaca\n",
            "Finished tokenizing:          3 samples\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 49.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting for chatbot: hc1\n",
            "Finished tokenizing:          3 samples\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 35.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting for chatbot: bard\n",
            "Finished tokenizing:          3 samples\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 39.58it/s]\n"
          ]
        }
      ],
      "source": [
        "max_len = 256 # put that we chose during training\n",
        "\n",
        "# test file generated from the models\n",
        "test_data_files = [\"tone_analysis_data_gpt.csv\",\n",
        "\"tone_analysis_data_gptlc.csv\",\n",
        "\"tone_analysis_data_alpaca.csv\",\n",
        "\"tone_analysis_data_hc1.csv\",\n",
        "\"tone_analysis_data_bard.csv\"]\n",
        "\n",
        "results_dict = {}\n",
        "\n",
        "for test_file in test_data_files:\n",
        "    chatbot_name = test_file.split('_')[3].split('.')[0]\n",
        "    print('Predicting for chatbot: {}'.format(chatbot_name))\n",
        "\n",
        "    df_test = pd.read_csv(test_file, encoding=\"cp1252\")\n",
        "\n",
        "    # tokenize the reviews\n",
        "    test_encodings = tokenizer(list(df_test['text']), truncation=True, padding=True, max_length=max_len, return_tensors='pt', add_special_tokens=True)\n",
        "    print('Finished tokenizing: {:>10,} samples\\n'.format(len(test_encodings)))\n",
        "\n",
        "    # create dataset loaders for ease of use\n",
        "    test_dataset = TensorDataset(test_encodings.input_ids, test_encodings.attention_mask)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader):\n",
        "            # get a batch\n",
        "            input_ids, attention_mask = batch\n",
        "            input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)\n",
        "            # predict\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=None)\n",
        "            logits = outputs.logits\n",
        "            # store logits\n",
        "            predictions.append(logits.cpu())\n",
        "    \n",
        "    # concatenate results from all batches\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    # ground truth labels are argmax of logits as predicted by BERT\n",
        "    bert_labels = np.argmax(predictions, axis=1).flatten()\n",
        "\n",
        "    # create a dataframe with the predictions and the ground truth labels\n",
        "    results = pd.DataFrame()\n",
        "    results['model_labels'] = df_test['label'] \n",
        "    results['bert_labels'] = bert_labels\n",
        "\n",
        "    results_dict[chatbot_name] = results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "u4q5Kv1nlY1D"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gpt\n",
            "----------------\n",
            "confusion_matrix:\n",
            " [[0 0 0]\n",
            " [5 3 1]\n",
            " [1 3 5]]\n",
            "accuracy:  0.4444444444444444\n",
            "f1 score:  0.3555555555555556\n",
            "\n",
            "\n",
            "gptlc\n",
            "----------------\n",
            "confusion_matrix:\n",
            " [[2 2 0]\n",
            " [4 3 1]\n",
            " [0 1 5]]\n",
            "accuracy:  0.5555555555555556\n",
            "f1 score:  0.5539682539682539\n",
            "\n",
            "\n",
            "alpaca\n",
            "----------------\n",
            "confusion_matrix:\n",
            " [[1 0 0]\n",
            " [4 4 3]\n",
            " [1 2 3]]\n",
            "accuracy:  0.4444444444444444\n",
            "f1 score:  0.41876750700280113\n",
            "\n",
            "\n",
            "hc1\n",
            "----------------\n",
            "confusion_matrix:\n",
            " [[2 0 0]\n",
            " [4 5 2]\n",
            " [0 1 4]]\n",
            "accuracy:  0.6111111111111112\n",
            "f1 score:  0.605169340463458\n",
            "\n",
            "\n",
            "bard\n",
            "----------------\n",
            "confusion_matrix:\n",
            " [[3 1 0]\n",
            " [2 5 3]\n",
            " [1 0 3]]\n",
            "accuracy:  0.6111111111111112\n",
            "f1 score:  0.6083333333333334\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
        "\n",
        "for chatbot_name, results in results_dict.items():\n",
        "    print(chatbot_name)\n",
        "    print('----------------')\n",
        "    cmat = confusion_matrix(results['bert_labels'], results['model_labels'])\n",
        "    print(\"confusion_matrix:\\n\", cmat)\n",
        "    print(\"accuracy: \", accuracy_score(results['bert_labels'], results['model_labels']))\n",
        "    print(\"f1 score: \", f1_score(results['bert_labels'], results['model_labels'], average='macro'))\n",
        "    print('\\n')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01d433b5612f4925869fcacb1aafed11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15a4f7ab5cd24a47af482904fe4c1b17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "195a3375b2204004b548cdd91316e5f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cc5c4ee950846c6ba1d25d87301499c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f9924c7bbb543ca8a7d167e3990f55b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c93408368361445080cdad6dddf1a3bb",
            "placeholder": "​",
            "style": "IPY_MODEL_5e2b04fbffa946278af5d44d6c8b398d",
            "value": " 28.0/28.0 [00:00&lt;00:00, 440B/s]"
          }
        },
        "2065b6339d8746b0a335396d3a16dd11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d475e4affb484953a77d12afb0b85eab",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd80c68536ed4d51b118d667e8be7537",
            "value": 28
          }
        },
        "213b68cdeb634b849938579906b64871": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb727e9810114f459a70b319f76bebc6",
            "placeholder": "​",
            "style": "IPY_MODEL_76c7986cbaf04f0198a99ec307a0c27e",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "219eff0d81a3479187a4674b58d77461": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d525b9bcdb4546b699981ca411c03054",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25a87c2c0dea4cfc839252e976d1da24",
            "value": 440449768
          }
        },
        "25a87c2c0dea4cfc839252e976d1da24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d8b2e11406c4df58e7ba2992dacd20d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36e818783c3643df885912802367e7c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49d6048613e54a399c342da92c557974": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54ffa10b88be4819acca71fa934b1678": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57e8db1f36814abb9a81be3b8e73469f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_195a3375b2204004b548cdd91316e5f6",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67d91181b11c4dcc9a1c4e10946bef6d",
            "value": 570
          }
        },
        "5acf2d10cb4340389667526bd91959cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_213b68cdeb634b849938579906b64871",
              "IPY_MODEL_57e8db1f36814abb9a81be3b8e73469f",
              "IPY_MODEL_a3b71073eabb4c48831b574cb763f15a"
            ],
            "layout": "IPY_MODEL_2d8b2e11406c4df58e7ba2992dacd20d"
          }
        },
        "5e2b04fbffa946278af5d44d6c8b398d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "613c38b31e1343b3a9aa55893309beaa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67d91181b11c4dcc9a1c4e10946bef6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "689ac92d11414ef29068fcebd1ec1b89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49d6048613e54a399c342da92c557974",
            "placeholder": "​",
            "style": "IPY_MODEL_e1f87b7f4d9e449796b257a5a48ef6c4",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "6e3607b7dc614e638968237b60d57221": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76c7986cbaf04f0198a99ec307a0c27e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86f68f17d8f645d3952a35f86a29eb13": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8987905efaff45c39188a0b543fa2343": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_689ac92d11414ef29068fcebd1ec1b89",
              "IPY_MODEL_219eff0d81a3479187a4674b58d77461",
              "IPY_MODEL_de54a24e5f8b4c3780146a5f65cb3ac9"
            ],
            "layout": "IPY_MODEL_01d433b5612f4925869fcacb1aafed11"
          }
        },
        "95dff7dae4854e00bff18e3b95532180": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e3607b7dc614e638968237b60d57221",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cce020115ed24d80ac88d8c89f141360",
            "value": 231508
          }
        },
        "a3b71073eabb4c48831b574cb763f15a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3f1492a5d344d4788a6deb7c8e8d632",
            "placeholder": "​",
            "style": "IPY_MODEL_54ffa10b88be4819acca71fa934b1678",
            "value": " 570/570 [00:00&lt;00:00, 10.2kB/s]"
          }
        },
        "a4b245840eb6414d90ac953fe77f1e0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aff5a0e8fbc54b72b00e763f397fb289": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b85a79a33f2d4547a32897bcf663595e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cc5c4ee950846c6ba1d25d87301499c",
            "placeholder": "​",
            "style": "IPY_MODEL_15a4f7ab5cd24a47af482904fe4c1b17",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "bb727e9810114f459a70b319f76bebc6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c93408368361445080cdad6dddf1a3bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cce020115ed24d80ac88d8c89f141360": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d475e4affb484953a77d12afb0b85eab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d525b9bcdb4546b699981ca411c03054": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6d29ba521e34d68b93125172e1fa0bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9575d7bb42c421cab9753a1878faa50",
            "placeholder": "​",
            "style": "IPY_MODEL_f803588ca5d840028855454d6269ff60",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "dd80c68536ed4d51b118d667e8be7537": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de54a24e5f8b4c3780146a5f65cb3ac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_613c38b31e1343b3a9aa55893309beaa",
            "placeholder": "​",
            "style": "IPY_MODEL_36e818783c3643df885912802367e7c1",
            "value": " 440M/440M [00:01&lt;00:00, 252MB/s]"
          }
        },
        "e16dab1f2b3d40dbb4e9831bae53f60e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6d29ba521e34d68b93125172e1fa0bd",
              "IPY_MODEL_95dff7dae4854e00bff18e3b95532180",
              "IPY_MODEL_faf80d9976dc4afeb953a8e419ace17c"
            ],
            "layout": "IPY_MODEL_86f68f17d8f645d3952a35f86a29eb13"
          }
        },
        "e1f87b7f4d9e449796b257a5a48ef6c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3f1492a5d344d4788a6deb7c8e8d632": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f06b651a7b7f45a39274b4f374e574c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4d929043b6345909fa0ea2b11d9ae5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b85a79a33f2d4547a32897bcf663595e",
              "IPY_MODEL_2065b6339d8746b0a335396d3a16dd11",
              "IPY_MODEL_1f9924c7bbb543ca8a7d167e3990f55b"
            ],
            "layout": "IPY_MODEL_a4b245840eb6414d90ac953fe77f1e0b"
          }
        },
        "f803588ca5d840028855454d6269ff60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9575d7bb42c421cab9753a1878faa50": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faf80d9976dc4afeb953a8e419ace17c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aff5a0e8fbc54b72b00e763f397fb289",
            "placeholder": "​",
            "style": "IPY_MODEL_f06b651a7b7f45a39274b4f374e574c8",
            "value": " 232k/232k [00:00&lt;00:00, 2.56MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
